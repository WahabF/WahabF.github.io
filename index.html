<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Abdulwahab Felemban | Autonomous Vehicles</title>
  <meta name="author" content="Abdulwahab Felemban">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.75em%22 font-size=%2280%22>ðŸš—</text></svg>">
</head>

<body>
  <div class="background-grid"></div>
  <div class="background-glow"></div>

  <header class="hero">
    <div class="hero__content">
      <p class="eyebrow">Autonomous Vehicles Â· Vision Â· AI Systems</p>
      <h1>Abdulwahab Felemban</h1>
      <p class="lead">
        Fourth-year Ph.D. candidate at KAUST Vision-CAIR with Prof. Mohammad Elhoseiny. I build multimodal, reasoning-centric AI systemsâ€”LLMs, VLMs, and MLLMsâ€”for perception, motion understanding, and decision-making, with a specialization in autonomous driving.
      </p>
      <div class="cta-row">
        <a class="cta primary" href="mailto:abdulwahab.felemban@kaust.edu.sa">
          <svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M3 6.5A2.5 2.5 0 0 1 5.5 4h13A2.5 2.5 0 0 1 21 6.5v11a2.5 2.5 0 0 1-2.5 2.5h-13A2.5 2.5 0 0 1 3 17.5v-11Zm2.3-.5 6.2 4.7c.3.23.7.23 1 0L18.7 6H5.3Z" fill="currentColor"/></svg>
          Email
        </a>
        <a class="cta ghost" href="#highlights">Latest work</a>
        <a class="cta ghost" href="CV_Felemban.pdf" target="_blank" rel="noreferrer">Full CV</a>
      </div>
      <div class="pill-strip">
        <span>LLMs Â· VLMs Â· MLLMs</span>
        <span>Reasoning-centric tuning</span>
        <span>Motion forecasting</span>
        <span>Vision-language driving</span>
        <span>Data engines & evaluation</span>
      </div>
    </div>
    <div class="hero__visual">
      <div class="profile-card">
        <div class="profile-glow"></div>
        <img src="images/profile.jpg" alt="Abdulwahab Felemban" class="profile-photo">
        <div class="profile-meta">
          <span>KAUST Â· Vision-CAIR</span>
          <span>Autonomy Research</span>
        </div>
      </div>
    </div>
  </header>

  <main class="page">
    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">About</p>
          <h2>Building trustable autonomy</h2>
        </div>
        <a class="inline-link" href="#contact">Letâ€™s collaborate â†’</a>
      </div>
      <p class="body-text">
        I design vision-centric autonomy stacks that stay reliable when conditions get messyâ€”harsh weather, rare edge cases, and the long tail of real-world driving. My work blends scalable data pipelines, foundation models for perception, and planning architectures that balance safety with smooth, human-like driving. Iâ€™m seeking a research internship across AI (LLMs, VLMs, MLLMs, motion perception/generation), with a strong track record in autonomy but open to broader AI roles.
      </p>
      <div class="grid three">
        <div class="card">
          <h3>Perception</h3>
          <p>Multimodal fusion (camera, LiDAR, radar) with self-supervision to keep detections crisp in night, fog, and glare.</p>
        </div>
        <div class="card">
          <h3>Reasoning</h3>
          <p>LLMs/VLMs/MLLMs with instruction tuning (SFT/DPO/GRPO) and VLAs to explain, predict, and act in dynamic scenes.</p>
        </div>
        <div class="card">
          <h3>Planning</h3>
          <p>Decision layers that reason about uncertainty, social cues, and comfortâ€”so vehicles drive assertively yet safely.</p>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Research focus</p>
          <h2>Multimodal AI with an autonomy edge</h2>
        </div>
      </div>
      <div class="grid two">
        <div class="card">
          <h3>Interests</h3>
          <p>LLMs, VLMs, MLLMs, and VLAs for perception and generation; motion forecasting; spatio-temporal models; reasoning-centric fine-tuning; large-scale dataset processing and evaluation.</p>
        </div>
        <div class="card">
          <h3>Tooling & Skills</h3>
          <p>Python, PyTorch, OpenCV; multi-GPU training and Slurm; AD tooling (open/closed-loop, BEV/trajectory representations); data curation pipelines; graph/spatio-temporal models; MATLAB and basic C++.</p>
        </div>
      </div>
    </section>

    <section class="section" id="highlights">
      <div class="section__header">
        <div>
          <p class="eyebrow">Highlights</p>
          <h2>Recent AI & autonomy work</h2>
        </div>
        <a class="inline-link" href="https://scholar.google.com" target="_blank" rel="noreferrer">Google Scholar â†’</a>
      </div>
      <div class="grid two">
        <div class="card highlight">
          <div class="badge">Robustness</div>
          <h3>All-weather vision stack</h3>
          <p>Training cameras to punch through fog, dust, and glare with adaptive sensor fusion and weather-conditioned prompts.</p>
          <div class="meta">Deployment-ready prototypes Â· Real-road validation</div>
        </div>
        <div class="card highlight">
          <div class="badge">Simulation</div>
          <h3>Scenario generation engine</h3>
          <p>Large-scale synthetic driving scenes that target long-tail risks, feeding closed-loop tests for planning policies.</p>
          <div class="meta">1000s of edge cases Â· Reduced regression churn</div>
        </div>
        <div class="card highlight">
          <div class="badge">Planning</div>
          <h3>Uncertainty-aware motion planner</h3>
          <p>Hierarchical planner that negotiates occlusions and social interactions while maintaining smooth ride quality.</p>
          <div class="meta">Faster convergence Â· Fewer disengagements</div>
        </div>
        <div class="card highlight">
          <div class="badge">LLMs/VLMs</div>
          <h3>iMotion-LLM & MLLM evaluations</h3>
          <p>Instruction-tuned motion prediction and benchmarking how vision-language models perceive fine-grained visual details.</p>
          <div class="meta">Reasoning-centric tuning Â· MLLM evaluation</div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Publications</p>
          <h2>Selected papers & patents</h2>
        </div>
      </div>
      <div class="list">
        <div class="list-item">
          <div class="badge">WACV 2026</div>
          <div>
            <h3>iMotion-LLM: Motion Prediction Instruction Tuning</h3>
            <p class="meta">A. Felemban et al. | Reasoning-aligned trajectory prediction via instruction tuning.</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">ArXiv 2025</div>
          <div>
            <h3>ReefNet: Large-Scale Benchmark for Hard Coral Classification</h3>
            <p class="meta">Y. Battach*, A. Felemban* et al. | 925k annotations; rigorous data verification pipeline.</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">Patent</div>
          <div>
            <h3>Real-Time Control of Mechanical Valves Using CV & ML</h3>
            <p class="meta">US Patent App. 18/021,241 (2023) with T.Y. Al-Naffouri et al.</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">ArXiv 2024</div>
          <div>
            <h3>How Well Can Vision Language Models See Image Details?</h3>
            <p class="meta">C. Gou, A. Felemban, F.F. Khan et al.</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">EUSIPCO 2020</div>
          <div>
            <h3>Robust 2D Indoor Positioning in the Presence of NLoS Signals</h3>
            <p class="meta">M.H. AlSharif, A. Felemban et al.</p>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Projects</p>
          <h2>Technical buildouts</h2>
        </div>
      </div>
      <div class="grid two">
        <div class="card">
          <h3>iMotion-VLM</h3>
          <p>End-to-end vision-language autonomous driving with multi-step reasoning and planning on nuScenes.</p>
        </div>
        <div class="card">
          <h3>InstructNuPlan & InstructWaymo</h3>
          <p>Safety- and feasibility-aligned trajectory datasets using vectorized BEV representations and instruction following.</p>
        </div>
        <div class="card">
          <h3>ReefNet</h3>
          <p>925K-annotation benchmark for coral identification; ViT/BEiT/BioCLIP/CLIP/SigLIP baselines with quality control.</p>
        </div>
        <div class="card">
          <h3>Smart-Tap</h3>
          <p>Real-time AI water valve control with spatio-temporal GCNs; prize-winning prototype for anticipatory actions.</p>
        </div>
        <div class="card">
          <h3>LLM/VLM fine-tuning</h3>
          <p>Reasoning-centric SFT/DPO/GRPO pipelines for instruction-following, motion prediction, and visual detail grounding.</p>
        </div>
        <div class="card">
          <h3>Scenario/data engines</h3>
          <p>Large-scale data curation, simulation stress-testing, and evaluation dashboards for both autonomy and general vision-language tasks.</p>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Experience</p>
          <h2>Where Iâ€™ve been learning</h2>
        </div>
      </div>
      <div class="timeline">
        <div class="timeline__item">
          <div class="timeline__dot"></div>
          <div class="timeline__content">
            <div class="edu">
              <img src="images/kaust.png" alt="KAUST logo" class="edu-logo">
              <div>
                <h3>Ph.D. Â· Electrical & Computer Engineering</h3>
                <p class="meta">KAUST â€” 01/2022â€“06/2027 (expected)</p>
                <p>Vision-CAIR with Prof. Mohammad Elhoseiny. Focus: deep learning, motion forecasting, reasoning for autonomous driving.</p>
              </div>
            </div>
          </div>
        </div>
        <div class="timeline__item">
          <div class="timeline__dot"></div>
          <div class="timeline__content">
            <div class="edu">
              <img src="images/kaust.png" alt="KAUST logo" class="edu-logo">
              <div>
                <h3>M.Sc. Â· Electrical & Computer Engineering</h3>
                <p class="meta">KAUST â€” 01/2020â€“01/2022 | GPA: 3.83/4.0</p>
                <p>Advisor: Prof. Tareq Al-Naffouri. Deep learning for human action prediction.</p>
              </div>
            </div>
          </div>
        </div>
        <div class="timeline__item">
          <div class="timeline__dot"></div>
          <div class="timeline__content">
            <div class="edu">
              <img src="images/kfupm.svg" alt="KFUPM logo" class="edu-logo">
              <div>
                <h3>B.Sc. Â· Electrical Engineering</h3>
                <p class="meta">KFUPM â€” 08/2014â€“12/2019 | GPA: 3.43/4.0</p>
                <p>Signal processing and wireless communications; AI surveillance senior project; heatstroke sensor junior project.</p>
              </div>
            </div>
          </div>
        </div>
        <div class="timeline__item">
          <div class="timeline__dot"></div>
          <div class="timeline__content">
            <div class="edu">
              <img src="images/gatech.svg" alt="Georgia Tech logo" class="edu-logo">
              <div>
                <h3>Exchange Semester Â· Electrical Engineering</h3>
                <p class="meta">Georgia Institute of Technology â€” 08/2018â€“12/2018</p>
                <p>Coursework in controls and signal processing; broadened international perspective.</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Awards</p>
          <h2>Recognitions & funding</h2>
        </div>
      </div>
      <div class="list">
        <div class="list-item">
          <div class="badge">Funding</div>
          <div>
            <h3>$1M research funding</h3>
            <p class="meta">NEOM OSSARI ($600k, 2024) + KAUST Translational Fund ($450k, 2022).</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">Awards</div>
          <div>
            <h3>Project wins</h3>
            <p class="meta">Start Smart 2 (1st, $9k, EcoStream, 2024); Digital Innovation Award 2 (1st, Smart-Tap, $21k, 2022); KFUPM Senior-Project (1st, AI Surveillance, 2019); SSI Poster (2nd, Indoor localization, 2019).</p>
          </div>
        </div>
        <div class="list-item">
          <div class="badge">Academic</div>
          <div>
            <h3>CEMSE Deanâ€™s List</h3>
            <p class="meta">Awarded to top 20% students, 2021â€“2022.</p>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section__header">
        <div>
          <p class="eyebrow">Service</p>
          <h2>Community contributions</h2>
        </div>
      </div>
      <div class="grid two">
        <div class="card">
          <h3>Reviewer</h3>
          <p>WACV 2026; ICCV 2025 Workshop Proceedings & CV4E; ACML 2024; SIGGRAPH Asia 2024.</p>
        </div>
        <div class="card">
          <h3>Organizer & Instructor</h3>
          <p>CVPR 2024 Workshop C3DV co-organizer; KAUST Academy 1-week AI instructor; KFUPM IEEE Publicity Chair; SSI indoor localization project.</p>
        </div>
      </div>
    </section>

    <section class="section" id="contact">
      <div class="section__header">
        <div>
          <p class="eyebrow">Contact</p>
          <h2>Letâ€™s drive the future together</h2>
        </div>
        <div class="pill-strip">
          <span>Speaking</span>
          <span>Collaboration</span>
          <span>Industry partnerships</span>
        </div>
      </div>
      <div class="contact-row">
        <div>
          <p class="body-text">
            I love teaming up on projects that push autonomous vehicles toward trustworthy, human-centered deployment. If youâ€™re building something boldâ€”or want a sparring partner for ideasâ€”reach out.
          </p>
          <div class="cta-row">
            <a class="cta primary" href="mailto:abdulwahab.felemban@kaust.edu.sa">
              <svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M3 6.5A2.5 2.5 0 0 1 5.5 4h13A2.5 2.5 0 0 1 21 6.5v11a2.5 2.5 0 0 1-2.5 2.5h-13A2.5 2.5 0 0 1 3 17.5v-11Zm2.3-.5 6.2 4.7c.3.23.7.23 1 0L18.7 6H5.3Z" fill="currentColor"/></svg>
              Email me
            </a>
            <a class="cta ghost" href="tel:+966569144133">
              <svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M7.5 3h3a1 1 0 0 1 1 1v3.5a1 1 0 0 1-1.2.98l-2.3-.46a9.5 9.5 0 0 0 5 5l.46-2.3a1 1 0 0 1 .98-1.2H17a1 1 0 0 1 1 1v3a2 2 0 0 1-2 2 13 13 0 0 1-13-13 2 2 0 0 1 2-2Z" fill="currentColor"/></svg>
              Call
            </a>
            <a class="cta ghost" href="https://www.linkedin.com/in/abdulwahab-felemban-b61469144/" target="_blank" rel="noreferrer">
              <img class="icon-img" src="images/linkedin.webp" alt="">
              LinkedIn
            </a>
            <a class="cta ghost" href="https://github.com/WahabF" target="_blank" rel="noreferrer">
              <img class="icon-img" src="images/github.png" alt="">
              GitHub
            </a>
            <a class="cta ghost" href="https://twitter.com/Ab_flm" target="_blank" rel="noreferrer">
              <img class="icon-img" src="images/x.webp" alt="">
              Twitter
            </a>
            <a class="cta ghost" href="https://www.instagram.com/aa_fel" target="_blank" rel="noreferrer">
              <img class="icon-img" src="images/instagram.png" alt="">
              Instagram
            </a>
            <a class="cta ghost" href="https://boxd.it/dx4h5" target="_blank" rel="noreferrer">
              <img class="icon-img" src="images/letterboxd.png" alt="">
              Letterboxd
            </a>
          </div>
          <p class="meta">Based in KAUST, Saudi Arabia Â· Open to research internships across AI (LLMs, VLMs, MLLMs, motion perception/generation) with depth in autonomy.</p>
        </div>
      </div>
    </section>
  </main>
</body>
</html>
